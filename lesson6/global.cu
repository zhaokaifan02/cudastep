#include <stdio.h>

//全局内存调用原理
//全局内存global是哪里都可以访问的，因为他在显卡的显存DRAM里，从DRAM里拿东西很慢。GPU可以借用L1缓存和L2缓存来实现减少从DRAM访问次数
//L1缓存小L2缓存大，GPU拿到一个东西后，先放到L1缓存里。如果调用时
//先看L1有没有，再看L2有没有，最后才从从DRAM里拿

//全局内存的访问模式有，合并于非合并之分（coalesced uncoalesced）
//合并访问指的是一个线程束对全局内存的一次访问请求导致最少数量的数据传输，否则是非合并访问
//合并度 degree of coalescing = 线程束请求的字节数 ÷ 由该请求导致的所有数据传输的字节数
//如果传输的字节都是要需要的，就是合并度 = 100% 则称为合并访问。合并度越高说明拿的越好设计的越精妙

//我们仅考虑一层L2缓存的情况下
//在此情况下，一次数据传输指的就是将32字节的数据从全局内存通过32字节L2 cache sector 传输到sm

//如果一个单精度浮点数栈4个字节，一个线程束32个线程，一次线程束需要32*4 = 128字节数据，即需要 128/32 = 4次

//那么什么情况会传输多4次呢

//数据传输原理。
//传输数据时，传输的开头必须是最小粒度的(32)整数倍,比如只能从 0 32 64 96等字节片段开始
//如果线程束请求的数据正好是0-127 或者 128-255等，就正好四次完全拿完，即我们拿的都是需要的，所以这种情况下就是合并访问

//所以为了保证每次都是32字节整数倍，因此我们在开辟内存时都是256内存的整数倍


__global__ void add(float *x, float* y, float *z)
{
    int n = threadIdx.x + blockIdx.x * blockDim.x;
    z[n] = x[n] + y[n];
}
//add<<<128,32>>>(x,y,z); 开辟了128个线程块，每个线程块32个线程
//第一个线程块是访问的的是x的0到31个元素，对应128字节的连续内存，首地址一定时256字节的整数倍，只需要4次即可完成，合并访问，没访问不好的东西

__global__ void add_permuted(float *x, float* y, float *z)
{
    int tid_permuted = threadIdx.x^0x1; //s交换两个相邻的数
    int n = tid_permuted + blockIdx.x * blockDim.x; //后面两个表示找到这个线程 
    //前面的tid_permuted 当前实际的地址
    z[n] = x[n] + y[n]; //这样访问组内乱序也没问题
    //因为这个线程束拿去时，已经从将32*4 = 128个字节放到L2里了
    //所以合并度也是100%
}

__global__ void add_offset(float* x, float *y, float* z)
{
    int n = threadIdx.x + blockIdx.x*blockDim.x + 1;//跨越式访问
    //第一次访问的是1-32，然后访问的是260-387内存，放在缓存中，这样就不对齐，会浪费
    z[n] = x[n] + y[n];
}
//合理规划即可
int main()
{

}