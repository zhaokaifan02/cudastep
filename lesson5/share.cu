#include <stdio.h>



int main()
{
    //回顾一下
    // 线程块的个数 grid_size 
    // 线程块里的线程个数 block_size 
    //每个block里的线程可以公用一块内存，被叫做 shared memory
    //寄存器与局部内存都是在单个线程里
    //同一个线程块中的所有线程都可以共享这块内存。
    //不能跨线程访问，共享内存的狠心特点就是减少对全局内存的访问

    //L1 和 L2 的缓存
    //共享内存是可以编程的缓存。（为什么是缓存，因为缓存访问的非常快）
    //L1 和L2缓存都是不可编程的缓存，不同芯片
    //不重要 没啥用

    //SM 及其占有率
    // 一个SM由多个SM组成,一个SM包含如下
    // 1. 一定数量寄存器。 2. 一定数量的共享内存。 3. 常量内存的缓存 
    // 4. 纹理和表面内存的缓存。5. L1缓存。 6. 2或4个线程调度器warp sheduler
    // 7. 执行核心 不讨论

    //SM占有率
    // 因为一个SM中的因为一个SM中的各种计算资源是有限的，所以SM的理论占有率越高越好（theoretical occupancy）
    // 1.一个SM中最多能拥有的线程块个数为Nb = 16，或者Nb = 32 由架构决定
    // 2. 一个SM中的最多线程个数为Nt = 2048 或 Nt = 1024
    // 因此很简单的一个想法就是，当并线规模很小时，核函数执行配置中的线程数量过少，SM当然用不满，所一下条论都是线程总数足够多的情况
    //1. 寄存器和共享内存的用量很少。此时，SM占有率完全由线程块大小决定。SM中线程的执行是由线程束决定的。一个线程束大小是32，所以设置线程块的大小最好是32的整数倍。计算时间时都是线程束决定的。这种情况下，可以获得100%的占有率。但实际上，不太可能，因为代码中寄存器或共享内存肯定是存在的
    //2. 有限的寄存器数量对占有率的约束。 2070中，一个SM能用的寄存器为64K 也就是64*1024个寄存器，如果我们希望一个SM中占有最大的线程（2048），那么每个线程只能由32个寄存器。当每个线程的寄存器的个数为64时，受限于寄存器的个数，只能开辟1024个线程，利用率为50%。实际情况下还有别的开销，应该是小于50%。同理当每个线程用的寄存器为128个时SM的占有率，为25%。
    //3. 有限的共享内存和寄存器时同理的，要合理选择共享内存的大小，核心是保证一个SM激活2048个线程，达到100%的占有率。一个如果一个线程块使用了超过48KB的共享内存，核函数无法运行。如果线程块的大小为128，那么一个SM要激活16个线程块才能达到2048进程满配。SM共享内存上限为48KB，所以分配个单个线程块的大小最多为48÷16 = 3KB。 如果一个线程块内存开多了开到了6，则SM中就只能塞8个线程块了，这样占有率就是50%。同理，共享内存开到12KB时，SM只能赛4个线程块了，则利用率为25%
    //可以用CUDA工具箱中的excel计算
    //也可以编译器中的 --ptxas-options =-v 看到每个核函数的寄存器使用数量
    //__launch_bounds__() 修饰符 也可以看到一个核函数的寄存器数量。每集极端情况下调参可能会用到
}